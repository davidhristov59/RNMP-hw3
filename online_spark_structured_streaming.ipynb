{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## This notebook sets up a Spark Structured Streaming application for real-time diabetes prediction\n",
    "\n",
    "This application loads the saved model, subscribes to the Kafka stream, and writes the predictions to a new topic."
   ],
   "id": "847f8ba8f533327d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:25.491658Z",
     "start_time": "2026-01-08T17:17:25.451438Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as f"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Spark Session with Kafka support",
   "id": "609cb6b2a8d2e126"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:25.636393Z",
     "start_time": "2026-01-08T17:17:25.503334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SparkSession.builder \\\n",
    "         .appName(\"StructuredStreamingSparkOnlinePrediction\") \\\n",
    "         .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "         .getOrCreate()"
   ],
   "id": "704f531efe385838",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the schema for the incoming data (same structure as the offline.csv)",
   "id": "58a889ddee16cd42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:25.689419Z",
     "start_time": "2026-01-08T17:17:25.674711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name=\"HighBP\", dataType=DoubleType()),\n",
    "        StructField(name=\"HighChol\", dataType=DoubleType()),\n",
    "        StructField(name=\"CholCheck\", dataType=DoubleType()),\n",
    "        StructField(name=\"BMI\", dataType=DoubleType()),\n",
    "        StructField(name=\"Smoker\", dataType=DoubleType()),\n",
    "        StructField(name=\"Stroke\", dataType=DoubleType()),\n",
    "        StructField(name=\"HeartDiseaseorAttack\", dataType=DoubleType()),\n",
    "        StructField(name=\"PhysActivity\", dataType=DoubleType()),\n",
    "        StructField(name=\"Fruits\", dataType=DoubleType()),\n",
    "        StructField(name=\"Veggies\", dataType=DoubleType()),\n",
    "        StructField(name=\"HvyAlcoholConsump\", dataType=DoubleType()),\n",
    "        StructField(name=\"AnyHealthcare\", dataType=DoubleType()),\n",
    "        StructField(name=\"NoDocbcCost\", dataType=DoubleType()),\n",
    "        StructField(name=\"GenHlth\", dataType=DoubleType()),\n",
    "        StructField(name=\"MentHlth\", dataType=DoubleType()),\n",
    "        StructField(name=\"PhysHlth\", dataType=DoubleType()),\n",
    "        StructField(name=\"DiffWalk\", dataType=DoubleType()),\n",
    "        StructField(name=\"Sex\", dataType=DoubleType()),\n",
    "        StructField(name=\"Age\", dataType=DoubleType()),\n",
    "        StructField(name=\"Education\", dataType=DoubleType()),\n",
    "        StructField(name=\"Income\", dataType=DoubleType())\n",
    "    ]\n",
    ")"
   ],
   "id": "4be3a12cf6af1ef6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading from Kafka topic 'health_data'",
   "id": "e9ca58f3e43df62c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:26.062436Z",
     "start_time": "2026-01-08T17:17:25.713257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = spark.readStream \\\n",
    "      .format(\"kafka\") \\\n",
    "      .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "      .option(\"subscribe\", \"health_data\") \\\n",
    "      .load()"
   ],
   "id": "b4a0c04667e49c34",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:26.098351Z",
     "start_time": "2026-01-08T17:17:26.091875Z"
    }
   },
   "cell_type": "code",
   "source": "df.printSchema()",
   "id": "e40cb31ddbaa48aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the saved model pipeline",
   "id": "a3439d7caa3d8fd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:28.556840Z",
     "start_time": "2026-01-08T17:17:26.108246Z"
    }
   },
   "cell_type": "code",
   "source": "model = PipelineModel.load(\"/home/jovyan/work/saved_models/best_diabetes_model\")",
   "id": "45a2aabe16ad4d1a",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parsing of the JSON message\n",
    "\n",
    " transforms the raw Kafka stream into a structured DataFrame with proper columns."
   ],
   "id": "50e8ce12de262252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:28.720395Z",
     "start_time": "2026-01-08T17:17:28.625980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parsed_df = df.select(\n",
    "    f.from_json(f.col(\"value\").cast(dataType=\"string\"), schema=schema).alias(\"data\")\n",
    ").select(\"data.*\")"
   ],
   "id": "78f98d3dc64866ab",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:28.762307Z",
     "start_time": "2026-01-08T17:17:28.753886Z"
    }
   },
   "cell_type": "code",
   "source": "parsed_df.printSchema()",
   "id": "3ed53d5f6c65132c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- HeartDiseaseorAttack: double (nullable = true)\n",
      " |-- PhysActivity: double (nullable = true)\n",
      " |-- Fruits: double (nullable = true)\n",
      " |-- Veggies: double (nullable = true)\n",
      " |-- HvyAlcoholConsump: double (nullable = true)\n",
      " |-- AnyHealthcare: double (nullable = true)\n",
      " |-- NoDocbcCost: double (nullable = true)\n",
      " |-- GenHlth: double (nullable = true)\n",
      " |-- MentHlth: double (nullable = true)\n",
      " |-- PhysHlth: double (nullable = true)\n",
      " |-- DiffWalk: double (nullable = true)\n",
      " |-- Sex: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Education: double (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Making predictions using the loaded model",
   "id": "8b205454a89f1fa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:28.918217Z",
     "start_time": "2026-01-08T17:17:28.783371Z"
    }
   },
   "cell_type": "code",
   "source": "predicted = model.transform(parsed_df)",
   "id": "4a6cf1bad67f1d9",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing the output DataFrame to write back to Kafka",
   "id": "c46d993d0dbc1442"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:17:28.947384Z",
     "start_time": "2026-01-08T17:17:28.935997Z"
    }
   },
   "cell_type": "code",
   "source": "output_df = predicted.selectExpr(\"to_json(struct(*)) AS value\")",
   "id": "1ad1911fc2574701",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Starting the streaming query to write predictions to a new Kafka topic 'health_data_predicted'",
   "id": "6c9dae540c0cfc5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:18:41.642858Z",
     "start_time": "2026-01-08T17:18:41.538379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = output_df.writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"topic\", \"health_data_predicted\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint\") \\\n",
    "    .start()"
   ],
   "id": "637fc9f287337148",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:18:25.823769Z",
     "start_time": "2026-01-08T17:18:25.618094Z"
    }
   },
   "cell_type": "code",
   "source": "query.awaitTermination()",
   "id": "eb3689150604397c",
   "outputs": [
    {
     "ename": "StreamingQueryException",
     "evalue": "[STREAM_FAILED] Query [id = f01979a8-ab5b-4fd8-85e1-1946e6fb1840, runId = 5796418d-3843-40f9-9dab-aae30f23e8f5] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mStreamingQueryException\u001B[0m                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawaitTermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/spark/python/pyspark/sql/streaming/query.py:201\u001B[0m, in \u001B[0;36mStreamingQuery.awaitTermination\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsq\u001B[38;5;241m.\u001B[39mawaitTermination(\u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m))\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawaitTermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:175\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    171\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mStreamingQueryException\u001B[0m: [STREAM_FAILED] Query [id = f01979a8-ab5b-4fd8-85e1-1946e6fb1840, runId = 5796418d-3843-40f9-9dab-aae30f23e8f5] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition."
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
